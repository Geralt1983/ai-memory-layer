#!/bin/bash
#
# Complete ChatGPT Memory System Deployment
# This script fully deploys and starts the 23,710 memory system
#

set -e

echo "ðŸš€ Deploying Complete ChatGPT Memory System Fix"
echo "================================================"

# Deploy the complete fix
cat > fix_api_complete.py << 'PYTHON_EOF'
#!/usr/bin/env python3
import sys
import os
sys.path.append('.')

# Load environment
from dotenv import load_dotenv
load_dotenv()

# Import and create the ChatGPT memory engine
from fixed_direct_chatgpt_api import create_chatgpt_memory_engine
print("ðŸš€ Initializing ChatGPT Memory System...")
memory_engine = create_chatgpt_memory_engine()
print(f"âœ… Loaded {len(memory_engine.memories)} ChatGPT memories")

# Import FastAPI and create app
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import Optional
import time

app = FastAPI(title="ChatGPT Memory API", version="2.0")
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Request models
class ChatRequest(BaseModel):
    message: str

class SearchRequest(BaseModel):
    query: str
    k: Optional[int] = 5

# All endpoints the frontend needs
@app.get("/health")
async def health():
    return {
        "status": "healthy",
        "memory_count": len(memory_engine.memories),
        "vector_store_entries": memory_engine.faiss_index.ntotal,
        "engine_type": "direct_chatgpt"
    }

@app.get("/stats")
async def stats():
    return memory_engine.get_stats()

@app.get("/memories/stats")
async def memories_stats():
    return memory_engine.get_stats()

@app.post("/memories/search")
async def search_memories(request: SearchRequest):
    try:
        results = memory_engine.search_memories(request.query, top_k=request.k)
        return {
            "memories": [
                {
                    "content": r.content,
                    "metadata": r.metadata,
                    "relevance_score": r.relevance_score
                }
                for r in results
            ],
            "total_count": len(results)
        }
    except Exception as e:
        return {"memories": [], "total_count": 0, "error": str(e)}

@app.post("/chat")
async def chat(request: ChatRequest):
    try:
        relevant_memories = memory_engine.search_memories(request.message, top_k=5)
        context = f"Found {len(relevant_memories)} relevant memories."
        return {
            "response": f"I searched {len(memory_engine.memories):,} ChatGPT memories. {context}",
            "context_used": True,
            "memories_searched": len(memory_engine.memories)
        }
    except Exception as e:
        return {"response": f"Error: {str(e)}", "error": str(e)}

@app.get("/")
async def root():
    return {
        "name": "ChatGPT Memory API",
        "memories_loaded": len(memory_engine.memories),
        "status": "ready"
    }

if __name__ == "__main__":
    import uvicorn
    print(f"\nðŸŒ Starting Complete ChatGPT API Server")
    print(f"ðŸ“Š Serving {len(memory_engine.memories):,} ChatGPT memories")
    uvicorn.run(app, host="0.0.0.0", port=8000, log_level="info")
PYTHON_EOF

echo "âœ… Created fix_api_complete.py"

# Now copy it to EC2 and start it
echo "ðŸ“¤ Deploying to EC2..."

# Use the deploy.sh mechanism to copy the file
cp fix_api_complete.py ~/Projects/ai-memory-layer/
cd ~/Projects/ai-memory-layer
./deploy.sh

echo "âœ… File deployed to EC2"
echo ""
echo "ðŸ“ To start the ChatGPT Memory System on EC2, run:"
echo ""
echo "ssh ubuntu@18.224.179.36"
echo "cd ~/ai-memory-layer"
echo "source venv/bin/activate"
echo "pkill -f python"
echo "python fix_api_complete.py"
echo ""
echo "ðŸŽ‰ Then visit http://18.224.179.36 to see 23,710 memories!"