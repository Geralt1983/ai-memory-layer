#!/usr/bin/env python3
"""
Test Full ChatGPT Memory Loader
===============================

Verification script to ensure the optimized loader correctly loads
all 23,710+ ChatGPT memories with proper FAISS index synchronization.
"""

import os
import sys
import time
from pathlib import Path
from datetime import datetime

# Add project root to Python path
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))


def test_environment_setup():
    """Test environment configuration and required files"""
    print("ğŸ”§ Testing Environment Setup")
    print("-" * 40)
    
    # Check environment variables
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        print("âŒ OPENAI_API_KEY not set")
        return False
    else:
        print(f"âœ… OPENAI_API_KEY configured ({api_key[:8]}...)")
    
    # Check required files
    required_files = [
        "./data/chatgpt_memories.json",
        "./data/faiss_chatgpt_index.index", 
        "./data/faiss_chatgpt_index.pkl"
    ]
    
    for file_path in required_files:
        if not os.path.exists(file_path):
            print(f"âŒ Missing file: {file_path}")
            return False
        else:
            size_mb = os.path.getsize(file_path) / 1024 / 1024
            print(f"âœ… {file_path} ({size_mb:.1f}MB)")
    
    print("âœ… Environment setup verification passed")
    return True


def test_data_integrity():
    """Test data file integrity and alignment"""
    print("\nğŸ” Testing Data Integrity")
    print("-" * 40)
    
    try:
        import json
        import faiss
        
        # Load and check FAISS index
        faiss_index = faiss.read_index("./data/faiss_chatgpt_index.index")
        faiss_count = faiss_index.ntotal
        print(f"âœ… FAISS index loaded: {faiss_count:,} vectors")
        
        # Load and check memory JSON
        with open("./data/chatgpt_memories.json", 'r') as f:
            memory_data = json.load(f)
        memory_count = len(memory_data)
        print(f"âœ… Memory JSON loaded: {memory_count:,} entries")
        
        # Check alignment
        if abs(faiss_count - memory_count) <= 100:  # Allow small discrepancy
            print(f"âœ… Good alignment: {abs(faiss_count - memory_count)} difference")
            
            # Expect around 23,710 memories from ChatGPT data
            if memory_count > 20000:
                print("âœ… Full ChatGPT dataset detected (>20k memories)")
            else:
                print(f"âš ï¸  Lower count than expected: {memory_count:,}")
        else:
            print(f"âŒ Poor alignment: {abs(faiss_count - memory_count)} difference")
            return False
        
        return True
        
    except Exception as e:
        print(f"âŒ Data integrity test failed: {e}")
        return False


def test_optimized_loader():
    """Test the optimized memory loader implementation"""
    print("\nğŸš€ Testing Optimized Memory Loader")
    print("-" * 40)
    
    try:
        from optimized_memory_loader import create_optimized_chatgpt_engine
        
        print("ğŸ“š Loading ChatGPT memory engine...")
        start_time = time.time()
        
        # Load the complete system
        memory_engine = create_optimized_chatgpt_engine()
        
        load_time = time.time() - start_time
        memory_count = len(memory_engine.memories) if memory_engine else 0
        
        print(f"â±ï¸  Load time: {load_time:.2f}s")
        print(f"ğŸ“Š Loaded memories: {memory_count:,}")
        
        # Verify expected count
        if memory_count > 20000:
            print("âœ… SUCCESS: Full ChatGPT dataset loaded")
        elif memory_count > 1000:
            print(f"âš ï¸  Partial load: {memory_count:,} memories (expected 23k+)")
        else:
            print(f"âŒ FAILED: Only {memory_count:,} memories loaded")
            return False, None
        
        # Performance check
        rate = memory_count / load_time if load_time > 0 else 0
        print(f"âš¡ Loading rate: {rate:.0f} memories/second")
        
        return True, memory_engine
        
    except Exception as e:
        print(f"âŒ Optimized loader test failed: {e}")
        import traceback
        traceback.print_exc()
        return False, None


def test_memory_engine_functionality(memory_engine):
    """Test core memory engine functionality"""
    print("\nğŸ§ª Testing Memory Engine Functionality")
    print("-" * 40)
    
    try:
        # Test get_stats - check if method exists
        if hasattr(memory_engine, 'get_stats'):
            stats = memory_engine.get_stats()
            print(f"ğŸ“Š Engine stats: {stats}")
        else:
            # Alternative stats gathering
            stats = {
                'total_memories': len(memory_engine.memories),
                'engine_type': 'optimized_chatgpt_loader'
            }
            print(f"ğŸ“Š Engine info: {stats}")
        
        # Verify stats alignment
        total_memories = stats.get('total_memories', 0)
        if total_memories != len(memory_engine.memories):
            print(f"âš ï¸  Stats mismatch: {total_memories} vs {len(memory_engine.memories)}")
        else:
            print(f"âœ… Stats aligned: {total_memories:,} memories")
        
        return True
        
    except Exception as e:
        print(f"âŒ Functionality test failed: {e}")
        return False


def test_search_performance(memory_engine):
    """Test search functionality and performance"""
    print("\nğŸ” Testing Search Performance")
    print("-" * 40)
    
    test_queries = [
        "python programming",
        "machine learning AI", 
        "ChatGPT conversation",
        "vector database FAISS",
        "OpenAI API integration"
    ]
    
    total_search_time = 0
    successful_searches = 0
    
    for i, query in enumerate(test_queries, 1):
        try:
            print(f"ğŸ” Test {i}: '{query}'")
            
            start_time = time.time()
            results = memory_engine.search_memories(query, k=5)
            search_time = time.time() - start_time
            
            total_search_time += search_time
            successful_searches += 1
            
            print(f"   â±ï¸  {search_time:.3f}s | ğŸ“ {len(results)} results")
            
            if results:
                top_result = results[0]
                content_preview = top_result.content[:80].replace('\n', ' ')
                score = getattr(top_result, 'relevance_score', 0.0)
                print(f"   ğŸ“„ Top: {content_preview}... (score: {score:.3f})")
            
        except Exception as e:
            print(f"   âŒ Search failed: {e}")
    
    if successful_searches > 0:
        avg_search_time = total_search_time / successful_searches
        print(f"\nğŸ“Š Search Performance Summary:")
        print(f"   â€¢ Successful searches: {successful_searches}/{len(test_queries)}")
        print(f"   â€¢ Average search time: {avg_search_time:.3f}s")
        print(f"   â€¢ Total search time: {total_search_time:.3f}s")
        
        if avg_search_time < 1.0:
            print("âœ… Excellent search performance (<1s average)")
        elif avg_search_time < 3.0:
            print("âœ… Good search performance (<3s average)")
        else:
            print("âš ï¸  Slow search performance (>3s average)")
        
        return True
    else:
        print("âŒ All searches failed")
        return False


def test_memory_content_quality(memory_engine):
    """Test the quality and variety of loaded memory content"""
    print("\nğŸ“ Testing Memory Content Quality")
    print("-" * 40)
    
    try:
        memories = memory_engine.memories[:100]  # Sample first 100
        
        # Check content variety
        content_lengths = [len(mem.content) for mem in memories if mem.content]
        roles = [getattr(mem, 'role', 'unknown') for mem in memories]
        types = [getattr(mem, 'type', 'unknown') for mem in memories]
        
        print(f"ğŸ“Š Content Analysis (first 100 memories):")
        print(f"   â€¢ Non-empty content: {len(content_lengths)}/100")
        print(f"   â€¢ Avg content length: {sum(content_lengths)/len(content_lengths) if content_lengths else 0:.0f} chars")
        print(f"   â€¢ Min/Max length: {min(content_lengths) if content_lengths else 0}/{max(content_lengths) if content_lengths else 0}")
        
        # Role distribution
        role_counts = {}
        for role in roles:
            role_counts[role] = role_counts.get(role, 0) + 1
        print(f"   â€¢ Role distribution: {role_counts}")
        
        # Type distribution  
        type_counts = {}
        for type_val in types:
            type_counts[type_val] = type_counts.get(type_val, 0) + 1
        print(f"   â€¢ Type distribution: {type_counts}")
        
        # Sample content
        if memories and memories[0].content:
            sample_content = memories[0].content[:200].replace('\n', ' ')
            print(f"ğŸ“„ Sample content: {sample_content}...")
        
        return True
        
    except Exception as e:
        print(f"âŒ Content quality test failed: {e}")
        return False


def run_comprehensive_test():
    """Run comprehensive test suite for ChatGPT memory loading"""
    print("ğŸ§ª Comprehensive ChatGPT Memory Loader Test")
    print("=" * 60)
    print(f"ğŸ• Started: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    total_start = time.time()
    tests_passed = 0
    total_tests = 6
    
    # Test 1: Environment setup
    if test_environment_setup():
        tests_passed += 1
    else:
        print("\nâŒ Environment setup failed - aborting tests")
        return False
    
    # Test 2: Data integrity
    if test_data_integrity():
        tests_passed += 1
    else:
        print("\nâŒ Data integrity failed - aborting tests")
        return False
    
    # Test 3: Optimized loader
    success, memory_engine = test_optimized_loader()
    if success and memory_engine:
        tests_passed += 1
    else:
        print("\nâŒ Optimized loader failed - aborting remaining tests")
        return False
    
    # Test 4: Memory engine functionality
    if test_memory_engine_functionality(memory_engine):
        tests_passed += 1
    
    # Test 5: Search performance
    if test_search_performance(memory_engine):
        tests_passed += 1
    
    # Test 6: Content quality
    if test_memory_content_quality(memory_engine):
        tests_passed += 1
    
    # Final results
    total_time = time.time() - total_start
    
    print("\n" + "=" * 60)
    print("ğŸ¯ Test Results Summary")
    print("=" * 60)
    print(f"ğŸ“Š Tests passed: {tests_passed}/{total_tests}")
    print(f"â±ï¸  Total test time: {total_time:.2f}s")
    print(f"ğŸ“ Memory count: {len(memory_engine.memories):,}")
    print(f"ğŸ Completed: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    if tests_passed == total_tests:
        print("\nğŸ‰ ALL TESTS PASSED!")
        print("âœ… Optimized ChatGPT memory loader is working correctly")
        print(f"ğŸš€ Ready to deploy with {len(memory_engine.memories):,} memories")
        return True
    else:
        print(f"\nâš ï¸  {total_tests - tests_passed}/{total_tests} tests failed")
        print("âŒ Issues need to be resolved before deployment")
        return False


if __name__ == "__main__":
    # Load environment
    try:
        from dotenv import load_dotenv
        if os.path.exists(".env"):
            load_dotenv()
    except ImportError:
        pass
    
    # Run comprehensive test
    success = run_comprehensive_test()
    
    # Exit with appropriate code
    sys.exit(0 if success else 1)